{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nudging.simulation import generate_datasets\n",
    "from sklearn.linear_model import BayesianRidge, LogisticRegression\n",
    "from nudging.model import BiRegressor\n",
    "from nudging.model import ProbModel, MDMModel, PCAModel\n",
    "from nudging.cate import get_cate_correlations\n",
    "from nudging.correlation import smooth_data\n",
    "from scipy.stats import spearmanr\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from copy import deepcopy\n",
    "from nudging.evaluate_outcome import evaluate_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(9817274)\n",
    "n_data = 5000\n",
    "default_param = {\n",
    "    \"noise_frac\": 0.5,\n",
    "    \"n_features_uncorrelated\": 5,\n",
    "    \"n_features_correlated\": 5,\n",
    "    \"avg_correlation\": 0.18,\n",
    "    \"n_rescale\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_datasets = generate_datasets(n_data, **default_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define models\n",
    "\n",
    "We define both the probabilistic model and a regression model (t-learner). In this case we use all the features that are available, which is 10 features in total, of which 2 are age and gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"mdm\": MDMModel(BayesianRidge()),\n",
    "    \"prob_log\": ProbModel(LogisticRegression()),\n",
    "    \"prob_bay\": ProbModel(BayesianRidge()),\n",
    "    \"t-learner\": BiRegressor(BayesianRidge()),\n",
    "    \"pca\": PCAModel(BayesianRidge()),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignore the many convergence warnings in the proba method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def run_model(model, data):\n",
    "    cate_perf, out_perf = evaluate_performance(model, data)\n",
    "    return np.mean(cate_perf), np.mean(out_perf)\n",
    "\n",
    "def get_results(models, datasets):\n",
    "    results_cate = defaultdict(lambda: [])\n",
    "    results_out = defaultdict(lambda: [])\n",
    "    for dataset in tqdm(datasets):\n",
    "        for name, model in models.items():\n",
    "            cate_perf, out_perf = run_model(model, dataset)\n",
    "            results_out[name].append(out_perf)\n",
    "            results_cate[name].append(cate_perf)\n",
    "    return results_out, results_cate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the average spearman-r correlations for the regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████████████████                                                                                    | 1183/5000 [51:45<2:52:34,  2.71s/it]"
     ]
    }
   ],
   "source": [
    "default_results = get_results(models, default_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot correlation of both models against each other\n",
    "\n",
    "From the plot below, it shows that the difference between the two models is a lot bigger with a higher number of features (~26%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CATE\")\n",
    "{name: np.mean(x) for name, x in default_results[0].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Outcome\")\n",
    "{name: np.mean(x) for name, x in default_results[1].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlations(attr, n_data_smooth=50):\n",
    "    if attr == \"n_features\":\n",
    "        param = deepcopy(default_param)\n",
    "        param.pop(\"n_features_uncorrelated\")\n",
    "        param.pop(\"n_features_correlated\")\n",
    "        datasets = generate_datasets(n_data, **param)\n",
    "        all_results = get_results(models, datasets)\n",
    "    elif attr in default_param:\n",
    "        param = deepcopy(default_param)\n",
    "        param.pop(attr)\n",
    "        datasets = generate_datasets(n_data, **param)\n",
    "        all_results = get_results(models, datasets)\n",
    "    else:\n",
    "        datasets = default_datasets\n",
    "        all_results = default_results\n",
    "    x = np.array([data.truth[attr] for data in datasets])\n",
    "    for channel in [0, 1]:\n",
    "        results = all_results[channel]\n",
    "        if channel == 0:\n",
    "            channel_name = \"CATE\"\n",
    "        else:\n",
    "            channel_name = \"Outcome\"\n",
    "        for linear in [True, False]:\n",
    "            idx = np.where([data.truth[\"linear\"] == linear for data in datasets])[0]\n",
    "            plt.figure(dpi=150)\n",
    "\n",
    "            if linear:\n",
    "                plt.title(\"Linear\")\n",
    "            else:\n",
    "                plt.title(\"Non-Linear\")\n",
    "            for name, res in results.items():\n",
    "                res = np.array(res)\n",
    "                xcor = spearmanr(x[idx], res[idx]).correlation\n",
    "                x_smooth, y_smooth = smooth_data(x[idx], res[idx], n_data=n_data_smooth)\n",
    "                plt.plot(x_smooth, y_smooth, label=f\"{name}: {xcor:.2f}\")\n",
    "            plt.xlabel(attr)\n",
    "            plt.ylabel(f\"{channel_name} correlation\")\n",
    "\n",
    "            plt.legend()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot correlations as a function of the dataset parameters\n",
    "\n",
    "Below we show differences between the two algorithms with respect to the properties of the dataset.\n",
    "\n",
    "First up is the amount of noise added to the feature matrix. Obviously, more noise means worse results. On the other hand, it seems like the t-learner is better at extracting information out of less noisy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlations(\"noise_frac\", n_data_smooth=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the next plot it seems that the number of samples a reasonably strong influence now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlations(\"n_samples\", n_data_smooth=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up is the `control_precision` parameter that signifies how much the outcome of the untreated/control group depends on the other features, with higher values indicating stronger relations. It looks like the probabilistic method has more trouble with stronger relations for the control group, but the difference is relatively uniform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlations(\"control_precision\", n_data_smooth=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last parameter to be looked at is `control_unique`. This controls how similar the responses are for the control group and the treatment group. If the parameter is 1, then it means that there is likely to be less correlation between the control and treatment responses. Differences are small, but it seems like the t-learner has a harder time with lower values, while the probabilistic method has a harder time with larger values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlations(\"control_unique\", n_data_smooth=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlations(\"n_features\", n_data_smooth=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlations(\"avg_correlation\", n_data_smooth=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlations(\"balance\", n_data_smooth=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlations(\"n_rescale\", n_data_smooth=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_linear(corr, datasets):\n",
    "    linear_res = [corr[i] for i in range(len(datasets)) if datasets[i].linear == True]\n",
    "    non_linear_res = [corr[i] for i in range(len(datasets)) if datasets[i].linear == False]\n",
    "    return linear_res, non_linear_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CATE\")\n",
    "{name: [np.mean(x) for x in split_linear(res, default_datasets)] for name, res in default_results[0].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Outcome\")\n",
    "{name: [np.mean(x) for x in split_linear(res, default_datasets)] for name, res in default_results[1].items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we have split the results in the linear and non-linear datasets for both the probabilistic and the regression model. We find that the regression model is about 15% better for the linear datasets. While both datasets become drastically worse with non-linearity added, the probabilistic method suffers more than the regression model. In this case, the regression model is about 54% better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
